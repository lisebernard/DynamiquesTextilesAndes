{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0c94e99",
   "metadata": {},
   "source": [
    "## Classification supervisée des images\n",
    "\n",
    "Un réseau de neurones est-il en mesure de détecter les armures des tissages ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c85dd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import shutil #copier fichier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f1b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268351b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../../data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a632a354",
   "metadata": {},
   "source": [
    "### Création du dataset --> Problème pour toutes les catégories le dataset est très déséquilibré\n",
    "\n",
    "Cas des techniques : \n",
    "- Catégorie \"fabric\" --> dataset très très déséquilibré --> rééquilibrer en mettant plus de photos pour certaines techniques ?\n",
    "- Catégorie \"technique\" --> trop précise\n",
    "- Catégorie \"structure\" --> 36 possibilités\n",
    "\n",
    "__Catégorie fabric__ : pour rééquilibrer le dataset on peut enlever les maquettes --> suppression de 2 balanced weave et de 156 warp faced cloth et créer des catégories plus grandes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08c9f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"textile_clean.csv\") as csv :\n",
    "    df_textile = pd.read_csv(csv, sep=\"\\t\")\n",
    "    \n",
    "#Pour rééquilibrer le dataset : suppression des maquettes\n",
    "for i in range(696):\n",
    "    if df_textile.loc[i, \"product\"] == \"Figure model\":\n",
    "        df_textile = df_textile.drop(i, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction pour voir le nombre de textile et d'images par catégorie. But : vérifier l'équilibre du dataset.\n",
    "def repartition_dataset(df, nom_colonne) :\n",
    "    #Récupération du nombre d'éléments par classe\n",
    "    colonne = df.loc[:,nom_colonne]\n",
    "    df1 = pd.DataFrame(colonne.value_counts())\n",
    "\n",
    "    #Récupération du nombre d'images associées à chaque classe\n",
    "    count_image = []\n",
    "    cats = list(df1.index)\n",
    "\n",
    "    for cat in cats : \n",
    "        df_cat = df.loc[lambda df: df['fabric'] == cat]\n",
    "        count = 0\n",
    "        for elt in df_cat['image'] : \n",
    "            elt = elt.split(',')\n",
    "            count += len(elt)\n",
    "        count_image.append(count)\n",
    "\n",
    "    df1['images'] = count_image\n",
    "    \n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9889c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "repartition_dataset(df_textile, 'fabric')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b46938-85af-4768-b820-b58493540e99",
   "metadata": {},
   "source": [
    "#### Modification des catégories pour avoir un dataset plus équilibré\n",
    "\n",
    "Passage de 22 catégories à 5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73276984",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_textile_yolo = df_textile.copy()\n",
    "\n",
    "for i in df_textile_yolo[['fabric']].columns:\n",
    "    df_textile_yolo[i].replace(\"Balanced weave, Weft-faced cloth\",\"Mixed weave\",inplace=True)\n",
    "    df_textile_yolo[i].replace(\"Warp-faced cloth, Weft-faced cloth\",\"Mixed weave\",inplace=True)\n",
    "    df_textile_yolo[i].replace(\"Balanced weave, Warp-faced cloth\",\"Mixed weave\",inplace=True)\n",
    "    df_textile_yolo[i].replace(\"Balanced weave, Warp-faced cloth, Weft-faced cloth\",\"Mixed weave\",inplace=True)\n",
    "    \n",
    "    df_textile_yolo[i].replace(\"Transposed warp with multiple interlaced wefts, Warp-faced cloth\",\"Warp-faced cloth\",inplace=True)\n",
    "    df_textile_yolo[i].replace(\"Plaiting, Warp-faced cloth\",\"Warp-faced cloth\",inplace=True)\n",
    "    df_textile_yolo[i].replace(\"Crossed warp weave, Warp-faced cloth\",\"Warp-faced cloth\",inplace=True)\n",
    "    df_textile_yolo[i].replace(\"Crossed warp weave\",\"Warp-faced cloth\",inplace=True) #?\n",
    "    \n",
    "    df_textile_yolo[i].replace(\"Plaiting, Weft-faced cloth\",\"Weft-faced cloth\",inplace=True)\n",
    "    df_textile_yolo[i].replace(\"Twining, Weft-faced cloth\",\"Weft-faced cloth\",inplace=True)\n",
    "\n",
    "    #D'Harcourt (1934) : catégorie qui reprend les fils entrelacés (et non deux couches perpendiculaires) : Tresses ou Nattes ? \n",
    "    #Mesh dans la base de données est catégorie fourre-tout (ILCA062 sont poupées avec tissage / certaines pièces sont tricots).\n",
    "    df_textile_yolo[i].replace(\"Oblique interlacing\",\"Mesh\",inplace=True)\n",
    "    df_textile_yolo[i].replace(\"Oblique interlacing, Tubular, Warp-faced cloth\",\"Mesh\",inplace=True)\n",
    "    df_textile_yolo[i].replace(\"Oblique interlacing, Weft-faced cloth\",\"Mesh\",inplace=True)\n",
    "    df_textile_yolo[i].replace(\"Oblique interlacing, Warp-faced cloth\",\"Mesh\",inplace=True)\n",
    "    df_textile_yolo[i].replace(\"Twining\",\"Mesh\",inplace=True)\n",
    "    df_textile_yolo[i].replace(\"Interknotting\",\"Mesh\",inplace=True)\n",
    "    df_textile_yolo[i].replace(\"Tubular\",\"Mesh\",inplace=True)\n",
    "    df_textile_yolo[i].replace(\"Transposed warp with multiple interlaced wefts\",\"Mesh\",inplace=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4671f2-77e7-4e1d-9220-dd0229005c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "repartition_dataset(df_textile_yolo, 'fabric')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de1b2e8-9d0a-4379-a177-336133b18e14",
   "metadata": {},
   "source": [
    "### Création d'un dataset qui classe les images selon leur armures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a2a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code qui répartit les images selon leur technique \n",
    "\n",
    "images_dir = \"images/images_jpg\" #images originales\n",
    "\n",
    "#Création d'un dossier dataset_technique\n",
    "dataset_dir = \"dataset_technique/dataset\"\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "\n",
    "#Création de sous-dossiers avec les noms des techniques\n",
    "folder_names = []\n",
    "for elt in list(set(df_textile_yolo.loc[:, \"fabric\"])) : \n",
    "    elt = elt.replace(\" \",\"\")\n",
    "    elt = elt.replace(\",\", \"\")\n",
    "    elt = elt.replace(\"-\", \"\")\n",
    "    folder_names.append(elt)\n",
    "folder_names\n",
    "\n",
    "for original_folder in folder_names:\n",
    "    path  = os.path.join(dataset_dir, original_folder) #concaténation chemin et nom du dossier\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "#Répartition des images selon leurs techniques : deux cas --> warp faced cloth (1 image) / autre (plusieurs images)\n",
    "#Parcourir le df, récupérer nom de la technique et noms images\n",
    "for i in range(696) :\n",
    "    try : #Pour ne pas prendre en compte les index qui ont sauté avec maquettes et les schémas .png\n",
    "        folder_name = df_textile_yolo.loc[i, \"fabric\"]\n",
    "        folder_name = folder_name.replace(\" \",\"\")\n",
    "        folder_name = folder_name.replace(\",\", \"\")\n",
    "        folder_name = folder_name.replace(\"-\", \"\")\n",
    "        #Ici si folder name = warpfacedcloth cas 1 image et sinon toutes les images\n",
    "\n",
    "        images = df_textile_yolo.loc[i, \"image\"]\n",
    "        images = images.replace(\"'\", \"\").replace(\"[\", \"\").replace(\"]\", \"\").replace(\" \", \"\").split(',')\n",
    "        for img in images : \n",
    "            shutil.copy(os.path.join(images_dir, img), os.path.join(dataset_dir,folder_name))\n",
    "    except :\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd57bc3f-dea7-4096-a856-64dba5cd8a1c",
   "metadata": {},
   "source": [
    "### Téléchargement du modèle et visualisation de ses composantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d688cd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Version YOLOv8\n",
    "model = YOLO('yolov8n-cls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aad5cca-ef65-4692-b9de-5f8b1b10b793",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Version YOLOv8\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6101be1-9073-4636-a755-3240828814c6",
   "metadata": {},
   "source": [
    "## Premier entrainement avec dataset tel quel\n",
    "\n",
    "Résultats enregistrés dans le dossier \"data/runs/classify/train_50epoch\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b53c82",
   "metadata": {},
   "source": [
    "### Partage des données train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4afc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = 'dataset_technique/dataset'\n",
    "train_dir = 'dataset_technique/data/train'\n",
    "val_dir = 'dataset_technique/data/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648ec2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b393c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_folders = [dir for dir in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, dir))]\n",
    "#On récupère la listes des noms des dossiers/classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edc09a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0a3b73",
   "metadata": {},
   "source": [
    "### Entraînement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709a42fa-01f0-41a0-99fa-02d1963f2007",
   "metadata": {},
   "outputs": [],
   "source": [
    "for original_folder in class_folders:\n",
    "    old_path  = os.path.join(dataset_dir, original_folder) #concaténation chemin et nom du dossier\n",
    "    new_folder_name = original_folder.split('-')[0]\n",
    "    new_path = os.path.join(dataset_dir, new_folder_name) #creation nouveau chemin\n",
    "    \n",
    "    os.rename(old_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a335d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour répartir les images d'entraînement et de validation dans des dossiers avec le bon nom\n",
    "for class_folder in class_folders:\n",
    "    class_path = os.path.join(dataset_dir, class_folder)\n",
    "    images = [image for image in os.listdir(class_path) if os.path.isfile(os.path.join(class_path, image))]\n",
    "    \n",
    "    train_img, val_img = train_test_split(images, test_size=0.2, random_state=42)\n",
    "    \n",
    "    train_subfolder_path = os.path.join(train_dir, class_folder)\n",
    "    val_subfolder_path = os.path.join(val_dir, class_folder)\n",
    "    \n",
    "    os.makedirs(train_subfolder_path, exist_ok=True)\n",
    "    os.makedirs(val_subfolder_path, exist_ok=True)\n",
    "    \n",
    "    for img in train_img:\n",
    "        shutil.copy(os.path.join(class_path, img), train_subfolder_path)\n",
    "        \n",
    "    for img in val_img:\n",
    "        shutil.copy(os.path.join(class_path, img), val_subfolder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5f4e63-6b14-4cb3-85f8-f2a641ebbdde",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###### Version pour YOLOv8\n",
    "results = model.train(data='dataset_technique/data',\n",
    "                      epochs=50,\n",
    "                      batch=64,\n",
    "                      dropout=0.1, \n",
    "                      seed = 42)\n",
    "                     ,#device='mps') #Entrainement sur la puce Apple M2 (et M1) \"Metal Performance Shaders\"\n",
    "\n",
    "#Bug. en utilisant MPS: error: 'mps.select' op failed to verify that all of {true_value, false_value, result} have same element type\n",
    "    # note: see current operation: %17 = \"mps.select\"(%16, %15, %14) : (tensor<1xi1>, tensor<1xf16>, tensor<1xf32>) -> tensor<1xf16>\n",
    "    #failed assertion 'expected a valid model URL' \n",
    "#Pas encore solutionné par Ultralytics : https://github.com/ultralytics/ultralytics/issues/7554 (issue du 13 janvier 2024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aaaf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualisation des résultats du modèle = résultat\n",
    "result = my_model('dataset_technique/data/val/Mixedweave/BML031_IMG_3428.jpg', visualize=True, save=True)\n",
    "#En jaune on voir les zones maximisées par neurones (pooling = plus on avance dans les couches moins on a de pixels)\n",
    "#Intéressant pour comprendre les choix de classification d'un réseau (couleur, motif, background...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3592e4-2488-46ae-a185-a5dfb339474b",
   "metadata": {},
   "source": [
    "#### Validation externe avec dataset de l'année dernière qui contient différentes techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e229f90-1808-4b57-b0fd-3a5bc3779f79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_model = YOLO('runs/classify/train_50epoch/weights/best.pt')\n",
    "dataset_val_out = 'dataset_technique/test_ext'\n",
    "images = [image for image in os.listdir(dataset_val_out) if image.endswith('.jpg')]\n",
    "for elt in images :\n",
    "    result = my_model(os.path.join(dataset_val_out, elt), visualize=True, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1d1f8a-bc66-4371-b576-eb8f00fba23c",
   "metadata": {},
   "source": [
    "## Deuxième entrainement avec dataset équilibré\n",
    "\n",
    "Résultats enregistrés dans le dossier \"data/runs/classify/train_eq_50epoch\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8948f371-3741-4022-85de-e71c6cdda223",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_folders = [dir for dir in os.listdir(dataset_dir) if os.path.isdir(os.path.join(dataset_dir, dir))]\n",
    "dict = {}\n",
    "for elt in class_folders :\n",
    "    count = 0\n",
    "    dir = f\"dataset_technique/dataset/{elt}\"\n",
    "    for path in os.listdir(dir):\n",
    "        if os.path.isfile(os.path.join(dir, path)):\n",
    "            count += 1\n",
    "    dict[elt]=count\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1917937-eb3c-48c9-b223-7e5cc60c4dff",
   "metadata": {},
   "source": [
    "Le dataset n'est pas équilibré, les tissages dominante chaîne sont largement supérieurs au reste des textiles ce qui risque de biaiser l'entraînement. Nous pouvons essayer de créer un dataset équilibré : contenant 54 images de chaque catégorie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddee2f7-04be-4c70-be04-28b64880efa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir2 = 'dataset_technique/data_eq/train'\n",
    "val_dir2 = 'dataset_technique/data_eq/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ad9bda-e3b6-4c92-a273-a4c8aadb921e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(train_dir2, exist_ok=True)\n",
    "os.makedirs(val_dir2, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24908cf4-a90d-42aa-be44-b9df9a8a8f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for original_folder in class_folders:\n",
    "    old_path  = os.path.join(dataset_dir, original_folder) #concaténation chemin et nom du dossier\n",
    "    new_folder_name = original_folder.split('-')[0]\n",
    "    new_path = os.path.join(dataset_dir, new_folder_name) #creation nouveau chemin\n",
    "    \n",
    "    os.rename(old_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa288b31-c445-4348-8e4a-77a31e18fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour répartir les images d'entraînement et de validation dans des dossiers avec le bon nom\n",
    "for class_folder in class_folders:\n",
    "    class_path = os.path.join(dataset_dir, class_folder)\n",
    "    images = [image for image in random.sample(os.listdir(class_path), 54) if os.path.isfile(os.path.join(class_path, image))]\n",
    "    #On ajoute random sample pour obtenir 54 images uniques aléatoirement dans les dossiers = équilibrage du dataset\n",
    "    \n",
    "    train_img, val_img = train_test_split(images, test_size=0.2, random_state=42)\n",
    "    \n",
    "    train_subfolder_path = os.path.join(train_dir2, class_folder)\n",
    "    val_subfolder_path = os.path.join(val_dir2, class_folder)\n",
    "    \n",
    "    os.makedirs(train_subfolder_path, exist_ok=True)\n",
    "    os.makedirs(val_subfolder_path, exist_ok=True)\n",
    "    \n",
    "    for img in train_img:\n",
    "        shutil.copy(os.path.join(class_path, img), train_subfolder_path)\n",
    "        \n",
    "    for img in val_img:\n",
    "        shutil.copy(os.path.join(class_path, img), val_subfolder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b50900-3b92-41a4-8c8d-2e51c4ff31d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Version pour YOLOv8\n",
    "results = model.train(data='dataset_technique/data_eq',\n",
    "                      epochs=50,\n",
    "                      batch=32,\n",
    "                      dropout=0.1)\n",
    "                     ,#device='mps') #Entrainement sur la puce Apple M2 (et M1) \"Metal Performance Shaders\"\n",
    "\n",
    "#Bug. en utilisant MPS: error: 'mps.select' op failed to verify that all of {true_value, false_value, result} have same element type\n",
    "    # note: see current operation: %17 = \"mps.select\"(%16, %15, %14) : (tensor<1xi1>, tensor<1xf16>, tensor<1xf32>) -> tensor<1xf16>\n",
    "    #failed assertion 'expected a valid model URL' \n",
    "#Pas encore solutionné par Ultralytics : https://github.com/ultralytics/ultralytics/issues/7554 (issue du 13 janvier 2024)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd08dd5-4ec6-4b14-8c8e-f04e7d7ea63d",
   "metadata": {},
   "source": [
    "#### Validation externe avec dataset de l'année dernière qui contient différentes techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36ff2ba-0c5a-4330-9070-512371e400e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_model = YOLO('runs/classify/train_eq_50epoch/weights/best.pt')\n",
    "dataset_val_out = 'dataset_technique/test_ext'\n",
    "images = [image for image in os.listdir(dataset_val_out) if image.endswith('.jpg')]\n",
    "for elt in images :\n",
    "    result = my_model(os.path.join(dataset_val_out, elt), visualize=True, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e45669-f9af-426c-b99e-0e3723fdfa7e",
   "metadata": {},
   "source": [
    "## Troisième entrainement avec dataset augmenté et équilibré\n",
    "\n",
    "Résultat enregistrés dans le dossier \"data/runs/classify/train_eq_augment_50epoch\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfa5aed-4097-4ad9-9215-3ebb3fde9a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir2 = 'dataset_technique/dataset_augment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0220c9c0-165a-4a3b-a915-9a9e8270c4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir3 = 'dataset_technique/data_augment/train'\n",
    "val_dir3 = 'dataset_technique/data_augment/val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b823aec-1acf-464c-872c-bb3d6d2002ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(train_dir3, exist_ok=True)\n",
    "os.makedirs(val_dir3, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc3dbd7-35fd-4931-ab42-84a1fd1556d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_folders = [dir for dir in os.listdir(dataset_dir2) if os.path.isdir(os.path.join(dataset_dir2, dir))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f68c20-c5d6-45bc-b7de-af47e2638430",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_folders = [dir for dir in os.listdir(dataset_dir2) if os.path.isdir(os.path.join(dataset_dir2, dir))]\n",
    "dict = {}\n",
    "for elt in class_folders :\n",
    "    count = 0\n",
    "    dir = f\"dataset_technique/dataset_augment/{elt}\"\n",
    "    for path in os.listdir(dir):\n",
    "        if os.path.isfile(os.path.join(dir, path)):\n",
    "            count += 1\n",
    "    dict[elt]=count\n",
    "print(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed806af2-eebb-4a7d-b645-487d0af73188",
   "metadata": {},
   "outputs": [],
   "source": [
    "for original_folder in class_folders:\n",
    "    old_path  = os.path.join(dataset_dir2, original_folder) #concaténation chemin et nom du dossier\n",
    "    new_folder_name = original_folder.split('-')[0]\n",
    "    new_path = os.path.join(dataset_dir2, new_folder_name) #creation nouveau chemin\n",
    "    \n",
    "    os.rename(old_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe99a26-589b-497f-a3d2-da702887db5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour répartir les images d'entraînement et de validation dans des dossiers avec le bon nom\n",
    "for class_folder in class_folders:\n",
    "    class_path = os.path.join(dataset_dir2, class_folder)\n",
    "    images = [image for image in random.sample(os.listdir(class_path),216) if os.path.isfile(os.path.join(class_path, image))]\n",
    "    #On ajoute random sample pour obtenir 216 images uniques aléatoirement dans les dossiers = équilibrage du dataset\n",
    "    \n",
    "    train_img, val_img = train_test_split(images, test_size=0.2, random_state=42)\n",
    "    \n",
    "    train_subfolder_path = os.path.join(train_dir3, class_folder)\n",
    "    val_subfolder_path = os.path.join(val_dir3, class_folder)\n",
    "    \n",
    "    os.makedirs(train_subfolder_path, exist_ok=True)\n",
    "    os.makedirs(val_subfolder_path, exist_ok=True)\n",
    "    \n",
    "    for img in train_img:\n",
    "        shutil.copy(os.path.join(class_path, img), train_subfolder_path)\n",
    "        \n",
    "    for img in val_img:\n",
    "        shutil.copy(os.path.join(class_path, img), val_subfolder_path)\n",
    "\n",
    "#172 en train / 44 en val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1cee76e-0f00-4556-a03a-7be80f959305",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Version pour YOLOv8\n",
    "results = model.train(data='dataset_technique/data_augment',\n",
    "                      epochs=50,\n",
    "                      batch=32,\n",
    "                      dropout=0.1)\n",
    "                     ,#device='mps') #Entrainement sur la puce Apple M2 (et M1) \"Metal Performance Shaders\"\n",
    "\n",
    "#Bug. en utilisant MPS: error: 'mps.select' op failed to verify that all of {true_value, false_value, result} have same element type\n",
    "    # note: see current operation: %17 = \"mps.select\"(%16, %15, %14) : (tensor<1xi1>, tensor<1xf16>, tensor<1xf32>) -> tensor<1xf16>\n",
    "    #failed assertion 'expected a valid model URL' \n",
    "#Pas encore solutionné par Ultralytics : https://github.com/ultralytics/ultralytics/issues/7554 (issue du 13 janvier 2024)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cc07f0-9ce4-4771-9652-23121c164173",
   "metadata": {},
   "source": [
    "#### Validation externe avec dataset de l'année dernière qui contient différentes techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071e20e5-445f-4f27-b556-f792d5a97bb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "my_model = YOLO('runs/classify/train_eq_augment_50epoch/weights/best.pt')\n",
    "dataset_val_out = '/Users/lise/memoire_tech/M2/data/dataset_technique/test_ext'\n",
    "images = [image for image in os.listdir(dataset_val_out) if image.endswith('.jpg')]\n",
    "for elt in images :\n",
    "    result = my_model(os.path.join(dataset_val_out, elt), visualize=True, save=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
